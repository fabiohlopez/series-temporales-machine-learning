{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pequeño tutorial de Pytorch\n",
    "\n",
    "En este notebook vamos a desarrollar algunos aspectos básicos de PyTorch para implementar modelos sencillos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en Numpy, donde tenemos un objeto fundamental (ndarray), pytorch tiene su propio objeto, que es muy similar a un array de Numpy, pero con mayores funcionalidades, fundamentalmente relacionadas al producto de tensores y calculo de gradientes (autograd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[[ 0.9365, -0.7600],\n",
      "         [ 0.5542,  1.6057],\n",
      "         [-0.5896,  0.5641]],\n",
      "\n",
      "        [[ 0.0469,  0.9249],\n",
      "         [ 0.5157,  0.5632],\n",
      "         [-0.7182, -1.3825]],\n",
      "\n",
      "        [[ 0.8840, -1.0303],\n",
      "         [-0.4446, -0.2949],\n",
      "         [-0.2217, -0.7158]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3,2) # Tensor de ceros\n",
    "b = torch.randn(3,3,2) # tensor de numeros aleatorios\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([[1,2],[3,4],[5,6]]) # tensor a partir de una lista\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4361, -0.7766,  0.6551],\n",
      "         [ 1.2985, -2.0382, -0.4470]],\n",
      "\n",
      "        [[ 0.5933,  0.6614,  0.7200],\n",
      "         [-1.3538,  1.8248,  0.6804]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "a = rng.normal(size=(2,2,3))\n",
    "b = torch.from_numpy(a)\n",
    "print(b)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las operaciones tipicas de numpy se pueden utilizar en pytorch: manejo de indices, operaciones aritmeticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4361, -0.7766,  0.6551],\n",
      "         [ 1.2985, -2.0382, -0.4470]],\n",
      "\n",
      "        [[ 0.5933,  0.6614,  0.7200],\n",
      "         [-1.3538,  1.8248,  0.6804]]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4361, -0.7766,  0.6551],\n",
       "        [ 1.2985, -2.0382, -0.4470],\n",
       "        [ 0.5933,  0.6614,  0.7200],\n",
       "        [-1.3538,  1.8248,  0.6804]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En vez de reshape, se utiliza el metodo view\n",
    "b.view(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4361, -0.7766],\n",
       "        [ 0.6551,  1.2985],\n",
       "        [-2.0382, -0.4470],\n",
       "        [ 0.5933,  0.6614],\n",
       "        [ 0.7200, -1.3538],\n",
       "        [ 1.8248,  0.6804]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# al igual que en Numpy, -1 es un comodín para redimensionar\n",
    "b.view(6,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4361, -0.7766,  0.6551,  1.2985, -2.0382, -0.4470,  0.5933,  0.6614,\n",
       "         0.7200, -1.3538,  1.8248,  0.6804], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.4360771 , -0.77658275,  0.65506992],\n",
       "        [ 1.29853472, -2.03820208, -0.4469787 ]],\n",
       "\n",
       "       [[ 0.59326631,  0.66141916,  0.72000364],\n",
       "        [-1.35378468,  1.82475483,  0.6804384 ]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para hacer un cast de un tensor en un ndarray, basta con utilizar el metodo numpy()\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd - Grafos computacionales y diferenciacion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1., requires_grad= True) # requires_grad significa que guarda y calcula el grafo computacional\n",
    "y = torch.tensor(2.,requires_grad= True)\n",
    "f = x + y  # Tensor con la suma\n",
    "z = torch.tensor(3., requires_grad= True)\n",
    "g = f*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.backward() # el metodo backward recorre el grafo hacia atras encontrando todas las derivadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las derivadas se calculan llamando simplemente llamando al atributo grad\n",
    "\n",
    "$$\n",
    "\\frac{dg}{dx} = \\frac{dg}{df}\\frac{df}{dx},\\ \\frac{dg}{dy} = \\frac{dg}{df}\\frac{df}{dy}, \\frac{dg}{dz} = \\frac{dg}{dz} \n",
    "$$\n",
    "$$\n",
    "\\frac{dg}{dx} = c \\times 1,\\ \\frac{dg}{dy} = z \\times 1, \\frac{dg}{dz} = f \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.) tensor(3.) tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad, y.grad, z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUS  - manejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para saber si tenemos una GPU disponible\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# En caso de tener una GPU disponible, basta con alojar los tensores en la GPU y operar con ellos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/Documents/Codes/series-temporales-machine-learning/STenv/lib/python3.10/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# En caso de tener una GPU disponible, basta con alojar los tensores en la GPU y operar con ellos\n",
    "a = torch.randn(1000,1000).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una buena practica es definir una variable que identifique el tipo de procesador y utilice la gpu por defecto\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# y utilizar el device \n",
    "a = torch.tensor(1., requires_grad= True, device= device) # como no disponemos de gpu, se alojara en la cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
